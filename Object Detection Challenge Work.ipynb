{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "selected_hardware_size": "small",
    "noteable": {
      "last_transaction_id": "bb7d1161-a4d1-4031-a145-0dd63e82cdca"
    }
  },
  "cells": [
    {
      "id": "fa2ef2da-dd1a-40af-a19f-64d0b5a0d8d1",
      "cell_type": "markdown",
      "source": "# Object Detection Challenge\nBelow is a project I completed as part of <b> Data-Driven Science's Object Detection Challenge</b>.\n\n## Step 1: Setup",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "84836c3e-399f-4916-a2b8-ea39fcbc7cab",
      "cell_type": "markdown",
      "source": "Below are some key set-up steps from <b>Data-Driven Science</b>:",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "d9cac3e5",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "output_collection_id": "d8dbc4e0-1eea-4695-ad3a-0f2e252e9782"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:43.893037+00:00",
          "start_time": "2023-06-17T18:45:57.278662+00:00"
        }
      },
      "execution_count": null,
      "source": "!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -qr requirements.txt",
      "outputs": []
    },
    {
      "id": "125650b3-454a-4af6-8d83-fd1d17f23652",
      "cell_type": "markdown",
      "source": "Now I will import the pytorch package and the utils package.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "93b65171-fab5-4658-8cc2-224c9731f02c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "92b9af43-8d89-4868-a106-30a8cab5d4ed"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:49.351620+00:00",
          "start_time": "2023-06-17T18:47:43.902329+00:00"
        }
      },
      "execution_count": null,
      "source": "import torch\nimport utils\ndisplay = utils.notebook_init()",
      "outputs": []
    },
    {
      "id": "33946b72-392a-4778-b78d-36af4b46b76f",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ac7db026-a2b0-4b93-b0d3-41710cfe4409"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:50.338176+00:00",
          "start_time": "2023-06-17T18:47:49.359839+00:00"
        }
      },
      "execution_count": null,
      "source": "##import the coco 128 dataset\n!bash data/scripts/get_coco128.sh\n",
      "outputs": []
    },
    {
      "id": "5fe8ad43-87cf-4644-8029-89ea239eae4a",
      "cell_type": "markdown",
      "source": "Now that I've set myself up with packages, I need to ensure that I've imported the Coco 128 dataset of images. I will do so by displaying the first image in the dataset, which should be some vegetables, according to <b>Data-Driven Science</b>.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "8bb2a056-f236-4967-9dd7-fb827761fcab",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "bee804b6-b640-4cf9-bb2b-d46d05bf0309"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:51.232425+00:00",
          "start_time": "2023-06-17T18:47:50.346869+00:00"
        }
      },
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt \nimport matplotlib.image as img\nimport os\n\n##get the list of all files in the directory\nfile_list = os.listdir(\"/etc/noteable/project/datasets/coco128/images/train2017\")\n\n##use matplotlib to display the image\ntestImage = img.imread(f\"/etc/noteable/project/datasets/coco128/images/train2017/{file_list[0]}\")\n\nplt.imshow(testImage)",
      "outputs": []
    },
    {
      "id": "b2183d90-ea3c-4455-abb5-d9304c820863",
      "cell_type": "markdown",
      "source": "## Step 2: Data Preparation\nI'll now move into exploring the dataset to evaluate the quality of it.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "60e61a5c-4e27-492a-a7ee-e71ebea86322",
      "cell_type": "markdown",
      "source": "To explain the structure of the dataset, I will answer a few questions about it.\n\nI've summarized this exploration in the table below, and have followed with further details:\n<table>\n  <tr>\n    <th>Question</th>\n    <th>Answer</th>\n  </tr>\n  <tr>\n    <td>What is the file type of the dataset?</td>\n    <td>Each image is a jpeg</td>\n  </tr>\n  <tr>\n    <td>What is the size of your dataset? (Youâ€™re on the right track if you find 128 images in the train set)</td>\n    <td>Francisco Chang</td>\n  </tr>\n  <tr>\n    <td>What are the dimensions of an image?</td>\n    <td>Francisco Chang</td>\n  </tr>\n  <tr>\n    <td>How many classes are there?</td>\n    <td>Francisco Chang</td>\n  </tr>\n  <tr>\n    <td>How are the labels formatted and stored in the data?</td>\n    <td>Francisco Chang</td>\n  </tr>",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "025f2d87-5970-431a-8d83-12ee169eec13",
      "cell_type": "markdown",
      "source": "### Data Exploration\n- What is the file type of the dataset?",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "b235f028-5b4a-4b15-adfc-78f722e5b611",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "python",
          "output_collection_id": "5ba03d42-f5f2-4262-87fb-2495d0ace6f3"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:52.007214+00:00",
          "start_time": "2023-06-17T18:47:51.850799+00:00"
        },
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "execution_count": null,
      "source": "#print out the first 10 files in the directory to understand what the file type of the dataset is\nprint(file_list[:10])\n",
      "outputs": []
    },
    {
      "id": "19e120a2-a614-4c0c-8c5d-ca6ffa430d1f",
      "cell_type": "markdown",
      "source": "From the output above, you can see that each image is a jpeg.\n\n- What is the size of the dataset?",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "cfdeb912-0408-42ed-a21a-4b1178513ceb",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "python",
          "output_collection_id": "1b1bd080-50a5-4f81-a361-257d2da89ae9"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:52.173300+00:00",
          "start_time": "2023-06-17T18:47:52.015404+00:00"
        }
      },
      "execution_count": null,
      "source": "# assign size\nsize = 0\n \n# assign folder path\nFolderpath = '/etc/noteable/project/datasets/coco128/images/train2017/'\n\n# get size\nfor path, dirs, files in os.walk(Folderpath):\n    for f in files:\n        fp = os.path.join(path, f)\n        size += os.path.getsize(fp)\n \n# display size\nprint(\"Folder size: \" + str(size))\n",
      "outputs": []
    },
    {
      "id": "a2ddaa0f-5ff2-427f-bc9e-6dfc83a34c8a",
      "cell_type": "markdown",
      "source": "The folder size of images is 6930964 bytes.\n\n- What are the dimensions of an image?\n",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "e4d2110a-48cc-49fd-9ef2-c965e03ed1c8",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "python",
          "output_collection_id": "fdfc34c7-f685-4c8b-b818-8e2c588c3d38"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:52.352393+00:00",
          "start_time": "2023-06-17T18:47:52.180216+00:00"
        }
      },
      "execution_count": null,
      "source": "## use the matplotlib library to get the dimensions of an image\nimg1 = plt.imread(f'/etc/noteable/project/datasets/coco128/images/train2017/{file_list[0]}')\nwidth, height = img1.shape[:2]\nprint(width,height)\n\nimg2 = plt.imread(f'/etc/noteable/project/datasets/coco128/images/train2017/{file_list[1]}')\nwidth2, height2 = img2.shape[:2]\nprint(width2,height2)\n",
      "outputs": []
    },
    {
      "id": "23473d54-a794-4bd9-a35a-0f2c7f6997ec",
      "cell_type": "markdown",
      "source": "The images are 480 pixels x 640 pixels.\n\n- How many classes are there?",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "4813449b-1b3d-4c29-a71a-7681d08f272f",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "5a689b16-2199-42f4-8d16-3b514d9e388c"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:47:52.522986+00:00",
          "start_time": "2023-06-17T18:47:52.359229+00:00"
        }
      },
      "execution_count": null,
      "source": "prefix=\"/etc/noteable/project/datasets/coco128/labels/train2017/\"\nfile_list = os.listdir(prefix)\n\nclasses=[]\n\nfor file in file_list:\n    with open(prefix+file,\"r\") as f:\n        contents=f.read()\n        classes.append(contents)\nprint(len(set(classes)))",
      "outputs": []
    },
    {
      "id": "ea931726-ac42-4b36-b28e-f1aea0f069b1",
      "cell_type": "markdown",
      "source": "There are 129 unique classess. The labels are formatted and stored in text files in the data.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "91601165-4440-455f-9c58-83f05a6495c7",
      "cell_type": "markdown",
      "source": "# Step 3: Image Augmentation\nNow, I will show an example of image augmentation for one of the images in the dataset.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "ae5b4b97-5f4d-491c-8cd3-8470e4136800",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "5476478a-104f-4801-b3cd-418da573465d"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:49:08.569793+00:00",
          "start_time": "2023-06-17T18:49:08.413646+00:00"
        }
      },
      "execution_count": null,
      "source": "from PIL import Image\nfrom pathlib import Path\nimport numpy as np\nimport torchvision.transforms as T",
      "outputs": []
    },
    {
      "id": "9c09f079-4f28-41e0-a270-0842ba50c570",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "97f1d77c-1954-4ef7-b9c7-31ee0474fa13"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T18:50:36.433097+00:00",
          "start_time": "2023-06-17T18:50:36.273614+00:00"
        }
      },
      "execution_count": null,
      "source": "plt.rcParams[\"savefig.bbox\"] = 'tight'\ntorch.manual_seed(0) #for randomly applied transforms",
      "outputs": []
    },
    {
      "id": "1cdaa270-9595-42e8-99c0-a85b79c4a86b",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "d0a93f24-7ac5-4a85-b243-866d90205e53"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:09:51.073770+00:00",
          "start_time": "2023-06-17T19:09:50.461127+00:00"
        }
      },
      "execution_count": null,
      "source": "##use matplotlib to display the original image\nimg_prefix=\"/etc/noteable/project/datasets/coco128/images/train2017/\"\nimg_list = os.listdir(img_prefix)\n\n##randomly select an image\nnum = np.random.randint(1,101)\ntestImage = img.imread(f\"{img_prefix}{img_list[num]}\")\n\n#use matplotlib to show the image\nplt.imshow(testImage)",
      "outputs": []
    },
    {
      "id": "a6a45497-ea65-4fcd-91d8-aa1989197a87",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f5c65984-0da7-4d3b-a9bd-96287cc85457"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:17:48.443381+00:00",
          "start_time": "2023-06-17T19:17:48.287941+00:00"
        }
      },
      "execution_count": null,
      "source": "##convert the image to a numpy array\narr=np.array(testImage)\n\n#we cannot resize the original image to be 128 x 128 because it does not own its data, but this is how it would work:\n# resized_image=testImage.resize((128,128))\n# resized_arr=np.array(resized_image)",
      "outputs": []
    },
    {
      "id": "e8b4a371-3c96-42df-ae3b-72078c3a178c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "2be94486-e3ed-4693-9f39-c51a5a97966d"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:17:51.469608+00:00",
          "start_time": "2023-06-17T19:17:50.878322+00:00"
        }
      },
      "execution_count": null,
      "source": "#Grayscale the image\ntest_img_pil=Image.fromarray(testImage)\ngrayscale_image=T.Grayscale()(test_img_pil)\n\n#display the grayscaled image\nplt.imshow(grayscale_image)",
      "outputs": []
    },
    {
      "id": "34581f8b-5e77-4e28-9c9d-6b6b7f091fcc",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "c2db2608-9080-44cf-8950-b29da5e3064d"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:17:54.622407+00:00",
          "start_time": "2023-06-17T19:17:54.022201+00:00"
        }
      },
      "execution_count": null,
      "source": "#Rotate the image\nrotate=T.RandomRotation(90)\n\nrotated_image=rotate(test_img_pil)\n\n#display the rotated image\nplt.imshow(rotated_image)",
      "outputs": []
    },
    {
      "id": "4dbe56d9-ac4f-4731-bd94-c153cb96aef7",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ec28cd35-5de7-4c5f-b7e6-c4191deb6053"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:19:09.503162+00:00",
          "start_time": "2023-06-17T19:19:08.916140+00:00"
        }
      },
      "execution_count": null,
      "source": "#Randomly flip the image\nflip=T.RandomHorizontalFlip()\n\nflipped_image=flip(test_img_pil)\n\n#display the rotated image\nplt.imshow(flipped_image)",
      "outputs": []
    },
    {
      "id": "9bb78908-85a1-4638-9bc2-f8b577715b16",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f5d14b77-1498-4da2-ab14-65ba3a5c9e55"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:23:42.562240+00:00",
          "start_time": "2023-06-17T19:23:41.903669+00:00"
        }
      },
      "execution_count": null,
      "source": "#normalize the original image\nnormalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\ntensor_image = T.ToTensor()(test_img_pil)\nnormalized_img_tensor=normalize(tensor_image)\nnormalized_PIL=T.ToPILImage()(normalized_img_tensor) # convert back to a PIL image \n\nplt.imshow(normalized_PIL)",
      "outputs": []
    },
    {
      "id": "2e40b33f-88ed-499c-96de-1343167a5e00",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "6eacb616-8dc5-4760-a901-9d0a2d7347dc"
        },
        "ExecuteTime": {
          "end_time": "2023-06-17T19:35:14.051856+00:00",
          "start_time": "2023-06-17T19:35:13.527822+00:00"
        }
      },
      "execution_count": null,
      "source": "#Create a pipeline of 3 transformations and display final image\ntransform1 = T.Resize([224,224])\ntransform2 = T.RandomCrop([128,128])\ntransform3 = T.RandomHorizontalFlip()\n\npipeline_transform= torch.nn.Sequential(transform1, transform2, transform3)\n\ntransformed_img=pipeline_transform(test_img_pil)\nplt.imshow(transformed_img)",
      "outputs": []
    }
  ]
}